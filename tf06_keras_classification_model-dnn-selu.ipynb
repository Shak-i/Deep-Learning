{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.3.4\n",
      "numpy 1.19.5\n",
      "pandas 1.1.5\n",
      "sklearn 0.24.2\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (5000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = (x - u) / std\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# x_train: [None, 28, 28] -> [None, 784]\n",
    "x_train_scaled = scaler.fit_transform(\n",
    "    x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_valid_scaled = scaler.transform(\n",
    "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_test_scaled = scaler.transform(\n",
    "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.models.Sequential()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\"))#把之前的relu改为了selu\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer = keras.optimizers.SGD(0.001),\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dense in module tensorflow.python.keras.layers.core:\n",
      "\n",
      "class Dense(tensorflow.python.keras.engine.base_layer.Layer)\n",
      " |  Just your regular densely-connected NN layer.\n",
      " |  \n",
      " |  `Dense` implements the operation:\n",
      " |  `output = activation(dot(input, kernel) + bias)`\n",
      " |  where `activation` is the element-wise activation function\n",
      " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
      " |  created by the layer, and `bias` is a bias vector created by the layer\n",
      " |  (only applicable if `use_bias` is `True`).\n",
      " |  \n",
      " |  Note: If the input to the layer has a rank greater than 2, then `Dense`\n",
      " |  computes the dot product between the `inputs` and the `kernel` along the\n",
      " |  last axis of the `inputs` and axis 1 of the `kernel` (using `tf.tensordot`).\n",
      " |  For example, if input has dimensions `(batch_size, d0, d1)`,\n",
      " |  then we create a `kernel` with shape `(d1, units)`, and the `kernel` operates\n",
      " |  along axis 2 of the `input`, on every sub-tensor of shape `(1, 1, d1)`\n",
      " |  (there are `batch_size * d0` such sub-tensors).\n",
      " |  The output in this case will have shape `(batch_size, d0, units)`.\n",
      " |  \n",
      " |  Besides, layer attributes cannot be modified after the layer has been called\n",
      " |  once (except the `trainable` attribute).\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # as first layer in a sequential model:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(16,)))\n",
      " |  # now the model will take as input arrays of shape (*, 16)\n",
      " |  # and output arrays of shape (*, 32)\n",
      " |  \n",
      " |  # after the first layer, you don't need to specify\n",
      " |  # the size of the input anymore:\n",
      " |  model.add(Dense(32))\n",
      " |  ```\n",
      " |  \n",
      " |  Arguments:\n",
      " |    units: Positive integer, dimensionality of the output space.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\")..\n",
      " |    kernel_constraint: Constraint function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      " |    The most common situation would be\n",
      " |    a 2D input with shape `(batch_size, input_dim)`.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      " |    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      " |    the output would have shape `(batch_size, units)`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dense\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with this\n",
      " |      layer as a list of Numpy arrays, which can in turn be used to load state\n",
      " |      into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |      Dtype used by the weights of the layer, set in the constructor.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of `tf.keras.metrics.Metric` instances tracked by the layer.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.utils.version_utils.LayerVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.layers.Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,410\n",
      "Trainable params: 271,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.6804 - accuracy: 0.7608 - val_loss: 0.5308 - val_accuracy: 0.8086\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.4853 - accuracy: 0.8247 - val_loss: 0.4647 - val_accuracy: 0.8356\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.4358 - accuracy: 0.8405 - val_loss: 0.4287 - val_accuracy: 0.8482\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.4046 - accuracy: 0.8536 - val_loss: 0.4047 - val_accuracy: 0.8550\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.3827 - accuracy: 0.8604 - val_loss: 0.3916 - val_accuracy: 0.8590\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.3644 - accuracy: 0.8667 - val_loss: 0.3791 - val_accuracy: 0.8650\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 0.3491 - accuracy: 0.8722 - val_loss: 0.3783 - val_accuracy: 0.8602\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 0.3376 - accuracy: 0.8769 - val_loss: 0.3702 - val_accuracy: 0.8708\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.3257 - accuracy: 0.8809 - val_loss: 0.3640 - val_accuracy: 0.8722\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.3158 - accuracy: 0.8841 - val_loss: 0.3468 - val_accuracy: 0.8816\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.3070 - accuracy: 0.8870 - val_loss: 0.3548 - val_accuracy: 0.8748\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.2982 - accuracy: 0.8905 - val_loss: 0.3509 - val_accuracy: 0.8748\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.2901 - accuracy: 0.8931 - val_loss: 0.3588 - val_accuracy: 0.8746\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.2817 - accuracy: 0.8971 - val_loss: 0.3441 - val_accuracy: 0.8784\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.2763 - accuracy: 0.8981 - val_loss: 0.3465 - val_accuracy: 0.8796\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 0.2690 - accuracy: 0.9014 - val_loss: 0.3414 - val_accuracy: 0.8784\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.2644 - accuracy: 0.9025 - val_loss: 0.3502 - val_accuracy: 0.8774\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.2576 - accuracy: 0.9052 - val_loss: 0.3570 - val_accuracy: 0.8772\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.2516 - accuracy: 0.9072 - val_loss: 0.3695 - val_accuracy: 0.8706\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.2459 - accuracy: 0.9098 - val_loss: 0.3447 - val_accuracy: 0.8820\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 0.2403 - accuracy: 0.9108 - val_loss: 0.3502 - val_accuracy: 0.8790\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard, earlystopping, ModelCheckpoint\n",
    "logdir = './dnn-selu-callbacks'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_model_file = os.path.join(logdir,\n",
    "                                 \"fashion_mnist_model.h5\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(logdir),\n",
    "    keras.callbacks.ModelCheckpoint(output_model_file,\n",
    "                                    save_best_only = True),\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3),\n",
    "]\n",
    "history = model.fit(x_train_scaled, y_train, epochs=100,\n",
    "                    validation_data=(x_valid_scaled, y_valid),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.6804234385490417, 0.4852588176727295, 0.4357646703720093, 0.40455174446105957, 0.3827029764652252, 0.36444544792175293, 0.34905922412872314, 0.3376479148864746, 0.3256559371948242, 0.31584829092025757, 0.3070375919342041, 0.29819342494010925, 0.2900788187980652, 0.28172820806503296, 0.2763221859931946, 0.2690071165561676, 0.2643806040287018, 0.2576029896736145, 0.2516016662120819, 0.24593989551067352, 0.24032410979270935], 'accuracy': [0.7608363628387451, 0.8246545195579529, 0.8405454754829407, 0.8536363840103149, 0.8604182004928589, 0.8666909337043762, 0.8722363710403442, 0.8769272565841675, 0.8808727264404297, 0.8841272592544556, 0.8869636654853821, 0.8905090689659119, 0.8931454420089722, 0.8971090912818909, 0.8980727195739746, 0.9014182090759277, 0.9025454521179199, 0.9052000045776367, 0.9072363376617432, 0.9098363518714905, 0.9107818007469177], 'val_loss': [0.5307890772819519, 0.46470585465431213, 0.4287204444408417, 0.40469515323638916, 0.3916364908218384, 0.37911054491996765, 0.37826240062713623, 0.370159775018692, 0.3639798164367676, 0.34676697850227356, 0.35480406880378723, 0.3509412109851837, 0.3588489592075348, 0.3441087603569031, 0.3464507460594177, 0.341439813375473, 0.35024493932724, 0.357023149728775, 0.3694687783718109, 0.3446963429450989, 0.3501564562320709], 'val_accuracy': [0.8086000084877014, 0.8356000185012817, 0.8482000231742859, 0.8550000190734863, 0.859000027179718, 0.8650000095367432, 0.8601999878883362, 0.8708000183105469, 0.8722000122070312, 0.881600022315979, 0.8748000264167786, 0.8748000264167786, 0.8745999932289124, 0.8784000277519226, 0.8795999884605408, 0.8784000277519226, 0.8773999810218811, 0.8772000074386597, 0.8705999851226807, 0.8820000290870667, 0.8790000081062317]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)\n",
    "\n",
    "# 1. 参数众多，训练不充分\n",
    "# 2. 梯度消失 -> 链式法则 -> 复合函数f(g(x))\n",
    "#    selu缓解梯度消失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38892924785614014, 0.8654000163078308]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
